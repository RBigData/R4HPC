---
title: "Using R on HPC Clusters &emsp;&emsp;&emsp;&emsp; Part 0 Site-scpecific Preamble"
author: "George Ostrouchov"
institute: "Oak Ridge National Laboratory"
date: "<br><br><br><br><br><br> August 17, 2022 <br><br><span style = 'font-size: 50%;'> Background Image: FRONTIER, First Top500 exascale system, announced June 2022</span>"
output:
  xaringan::moon_reader:
    css: ["default", "default-fonts", "my-theme.css", "widths.css"]
    lib_dir: libs
    includes:
      after_body: insert-logo.html
    nature:
      titleSlideClass: ["right", "inverse"]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
    self_contained: true
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
xaringanExtra::use_xaringan_extra(c("tile_view", "animate_css", "tachyons"))
hook_source <- knitr::knit_hooks$get('source')
knitr::knit_hooks$set(source = function(x, options) {
  x <- stringr::str_replace(x, "^[[:blank:]]?([^*].+?)[[:blank:]]*#<<[[:blank:]]*$", "*\\1")
  hook_source(x, options)
})
```
# Get this presentation: 
`git clone https://github.com/RBigData/R4HPC.git`

* Open `R4HPC_Part0_OLCF_CADES_ALCF_NERSC.html` in your web browser  
* `?` toggles help  
<br>

Slack workspace link for this workshop was emailed to you. 
<br><br><br>

<small>
*Many thanks to my colleagues and former colleagues who contributed to the software and ideas presented here. See the RBigData Organization on Github: https://github.com/RBigData. Also, many thanks to all R developers of packages used in this presentation.*

*This manuscript has been authored by UT-Battelle, LLC under Contract No. DE-AC05-00OR22725 with the U.S. Department of Energy. The United States Government retains and the publisher, by accepting the article for publication, acknowledges that the United States Government retains a non-exclusive, paid-up, irrevocable, world-wide license to publish or reproduce the published form of this manuscript, or allow others to do so, for United States Government purposes. The Department of Energy will provide public access to these results of federally sponsored research in accordance with the DOE Public Access Plan (http://energy.gov/downloads/doe-public-access-plan).*</small>

???
The first hands-on session will do this also
<br><br><br><br><br><br><br><br>

Of course, any mistakes are mine alone!!

---
# Using R on HPC Clusters Webinar

* A basic workflow for how to use R on an HPC cluster
* Speed up R scripts with parallel computing concepts
* Many packages in R offer parallel computing abstractions, yet they use a much smaller set of underlying approaches: 
   * multithreading in compiled code, the unix fork, and MPI
* We take a narrow path to focus on the direct approaches
* Targeted for current users of OLCF, CADES, ALCF and NERSC
* Others are welcome to the lecture portions but will not be able to participate in all of the hands-on activities

#### Objectives 

* Learn a workflow to edit R code on your laptop and run it on an HPC cluster

* Learn how to use multicore and distributed parallel concepts in R on an HPC cluster system

???
* The workflow is half the battle to manage frustration of new users
* HPC cluster has several parallel resources used simulatneously
* On a laptop, often one choice among approaches is made
* Many abstractions are a layer above the basics
   * foreach, dopar, futures
   * Understanding basics helps understanding the abstractions 
   * Add another layer to a complex situation - harder debug
   * Basics are closer to HPC community (largely C and C++) terminology
      * Helps understanding HPC language

* Some of the exercises can be done on a laptop but miss the important workflow socialization

---
background-image: url(pics/01-intro/WorkflowCluster.jpg)
background-position: top right
background-size: 20%

## The Clusters

ORNL OLCF Andes
* 704 nodes, each with two 16-core 3.0 GHz AMD EPYC processors

ORNL CADES SHPC Condos
* ~650 nodes, a mix of x86_64 processors with 32 to 128 cores
* New LMOD software stack (see https://docs.cades.ornl.gov/#condos/software/bash-env/#new-software-stack)

LBL NERSC Perlmutter 
* 3,072 CPU-only nodes, AMD EPYC Milan, each with 64 cores
* 1,536 GPU-accelerated nodes, AMD EPYC Milan + 4 NVIDIA A100 GPU

ANL ACLF Polaris
* 560 nodes, each with AMD EPYC Milan (32 cores)  + 4 NVIDIA A100 GPU

---
# Access to HPC Clusters

* DOE OLCF https://docs.olcf.ornl.gov/accounts/accounts_and_projects.html
* DOE ORNL CADES https://cades.ornl.gov/
* DOE ALCF https://www.alcf.anl.gov/support-center/account-and-project-management/allocations

* DOE NERSC https://www.nersc.gov/users/accounts/allocations/
* NSF XSEDE to ACCESS https://www.xsede.org/

* A cluster at your institution  

* International:
   * EU PRACE https://prace-ri.eu/hpc-access/ (for example IT4I.cz https://www.it4i.cz/en/for-users/computing-resources-allocation) 
   * UK, Switzerland, Japan, and many others have similar programs

 
---
background-image: url(pics/01-intro/WorkflowCluster.jpg)
background-position: top right
background-size: 20%

## Job Submission on Cluster

* Command line submission
* Shell script submission (preferred)

.pull-left[
#### Slurm (Andes, CADES, Perlmutter)
<mark>sbatch  *your-shell-script.sh* </mark>

<mark>squeue  -u *uid*</mark>

<mark>scancel  *jobnumber*</mark>
]
.pull-right[
#### Cobalt - PBS (Polaris)
<mark>qsub   *your-shell-script.sh* 

<mark>qstat -u *uid*

<mark>qdel  *jobname*</mark>
]  
<br>
* **module** to set software environment (PATH)
  * <mark>*module list*</mark> - list what is loaded
  * <mark>*module avail*</mark> - list what is available
  * <mark>*module load r*</mark>
  
???
* More explanation for scripts you will see
  
---
# Acknowledgments

*This research used resources of the Oak Ridge Leadership Computing Facility, which is a DOE Office of Science User Facility supported under Contract DE-AC05-00OR22725.*

*This research used resources of the Compute and Data Environment for Science (CADES) at the Oak Ridge National Laboratory, which is supported by the Office of Science of the U.S. Department of Energy under Contract No. DE-AC05-00OR22725"*

*Slides are made with the xaringan R package. It is an R Markdown extension based on the JavaScript library remark.js.*

