<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>High Performance Statistical Computing   with R</title>
    <meta charset="utf-8" />
    <meta name="author" content="George Ostrouchov" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link href="libs/tile-view/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view/tile-view.js"></script>
    <link href="libs/animate.css/animate.xaringan.css" rel="stylesheet" />
    <link href="libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <link rel="stylesheet" href="my-theme.css" type="text/css" />
    <link rel="stylesheet" href="widths.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: right, inverse, title-slide

.title[
# High Performance Statistical Computing <br> with R
]
.author[
### George Ostrouchov
]
.institute[
### Oak Ridge National Laboratory, University of Tennessee,<br> and Charles University
]
.date[
### <br> Robust22 <br><br> Volyně, CZ, June 12, 2022 <br><br><span style="font-size: 50%;"> Background Image: FRONTIER, First Top500 exascale system, announced June 2022</span>
]

---



# Get this presentation:
`https://github.com/RBigData/ROBUST2022/archive/refs/heads/main.zip`

* Unzip

* Open &lt;br&gt;&lt;br&gt;`ROBUST2022-main/Robust2022.html` &lt;br&gt;&lt;br&gt; in your web browser

* In this class, we will also show how to get it more directly with **git**
---
# Why HPSC?

* More memory  

* Faster code

* Statisticians are needed in HPC

# What is Fast Enough?

* Methodology: seconds

* Optimize parameters: 100 to 1000 `\(\times\)` methodology

* Bootstrap uncertainty in optimization: 100 to 1000 `\(\times\)` optimization

### Faster code can do more
---

## Part I: Software Installatons on Laptop
## Part II: Workflow from Laptop to Cluster
## Part III: Parallel Hardware
## Part IV: Parallel Software
## Part V: Shared Memory Tools
## Part VI: Distributed Memory Tools
---

## Part I: &lt;br&gt; &lt;br&gt; Software Installatons on a Laptop for work with a Cluster
---
### For work with a cluster
* Mac
   * R, RStudio
   
   * terminal, git (in Xcode app)
   
* Windows
   * R, RStudio
   
   * putty
   
   * git
   
   * WinSCP
---

## Links for Software on Laptop and Access

* RStudio:  [RStudio Desktop Free](https://www.rstudio.com/products/rstudio/download/) 

* git: [RStudio with Git](https://support.rstudio.com/hc/en-us/articles/200532077-Version-Control-with-Git-and-SVN)

* ssh: [Wikipedia ssh](https://en.wikipedia.org/wiki/Secure_Shell)

* IT4Innovations:
   * [Get Project](https://docs.it4i.cz/general/applying-for-resources/)
      * [Example application](pics/IT4I/DD-form.pdf)

   * [Access](https://docs.it4i.cz/general/shell-and-data-access/)
   
   * [ssh](https://docs.it4i.cz/general/accessing-the-clusters/shell-access-and-data-transfer/ssh-key-management/)

   * [Windows](https://docs.it4i.cz/general/accessing-the-clusters/shell-access-and-data-transfer/putty/)

* Karlova Universita MFF:

   * [Sněhurka](https://cluster.karlin.mff.cuni.cz/pouziti-clusteru/)

   * [Chiméra](https://www.mff.cuni.cz/cs/verejnost/aktuality/otevreni-fakultniho-hpc-clusteru)

---
## For faster R on your macOS laptop


```r
## Default BLAS from Netlib
&gt; x = matrix(rnorm(1e7), nrow = 1e4)
&gt; system.time(crossprod(x))
   user  system elapsed 
  6.752   0.023   6.801 
```
* Apple vecLib (via Xcode) can be swapped in  

`ln -sf /Library/Frameworks/R.framework/Resources/lib/libRblas.veclib.dylib /Library/Frameworks/R.framework/Resources/lib/libRblas.dylib`
* Or `brew install openblas`, and link OpenBLAS to R

`ln -sf /usr/local/opt/openblas/lib/libopenblas.dylib /Library/Frameworks/R.framework/Resources/lib/libRblas.dylib`
.pull-left[

```r
## vecLib
&gt; system.time(crossprod(x))
   user  system elapsed 
  0.666   0.003   0.120 
```
]
.pull-right[

```r
## OpenBLAS
   &gt; system.time(crossprod(x))
      user  system elapsed 
     0.822   0.042   0.121 
```
]
---
## For faster R on your Windows laptop


Assessing R performance with optimized BLAS across three operating systems   [link](https://thomasmcrow.com/blog/2021-08-optimized-blas-in-r/)

&lt;br&gt;

Building R 4+ for Windows with OpenBLAS    [link](https://www.r-bloggers.com/2020/05/building-r-4-for-windows-with-openblas/)

---

# Part II:  &lt;br&gt; &lt;br&gt; Workflow from Laptop to Cluster
---
## Working with a remote cluster using R

&lt;img src="pics/01-intro/Workflow.jpg" height="500" /&gt;

---
background-image: url(pics/01-intro//Workflow.jpg)
background-position: top right
background-size: 20%

## Why?

### Laptop RStudio
* Familiar custom editing environment (Windows, Mac, Unix)
* Interactive Syntax checking

### GitHub/GitLab
* Portability to remote computing
* Version control
* Collaboration

### Cluster unix
* Same environment for all
* Batch job submission

&lt;br&gt;&lt;br&gt;

#### Advanced: interactive multinode development and debugging in RStudio
* Available now, but unstable (launchr, pbdCS, pbdRPC, remoter)
* Needs further development and standardization

---
background-image: url(pics/01-intro//WorkflowRunning.jpg)
background-position: top right
background-size: 20%

## Running Distributed on a Cluster

&lt;img src="pics/01-intro/BatchRonCluster.jpg" height="500" /&gt;

---
background-image: url(pics/01-intro//WorkflowCluster.jpg)
background-position: top right
background-size: 20%

# Clusters are Linux systems
* Linux is one of many descendants of original Unix. MacOS is another.

* Like all file systems, Linux files are organized as a tree.

* When in a terminal, you are talking to a *shell* program (*bash* is most common)

   * Each command can have a list of *options* and a list of *arguments*
   * *Standard input* and *standard output* of a command is the terminal but can be redirected
   * **&lt;**, **&lt;&lt;**, **&gt;**, **&gt;&gt;** redirect standard input and output
   * *command1* **|** *command2* pipes standard output1 to standard input2
   * Commands are looked up in directories listed in your PATH variable (try "echo $PATH")
   * $ means substitute variable value
   * *export* lists (or sets) all your variables and their values

* There are many resources on the web to learn Linux basics

---
background-image: url(pics/01-intro//WorkflowCluster.jpg)
background-position: top right
background-size: 20%

# Some useful Linux commands
* &lt;mark&gt;pwd&lt;/mark&gt;  Show curent directory
* &lt;mark&gt;ls&lt;/mark&gt;  List files in current directory
  * &lt;mark&gt;ls -a&lt;/mark&gt; Include files that start with &lt;mark&gt;.&lt;mark&gt;
  * &lt;mark&gt;ls -l&lt;/mark&gt; Long listing with *permissions*, *owners*, and *last change time*
* &lt;mark&gt;cd *dir_name* &lt;/mark&gt; Change directory to dir_name
* &lt;mark&gt;mkdir *dir_name*&lt;/mark&gt; Creates directory dir_name
* &lt;mark&gt;rmdir *dir_name*&lt;/mark&gt; Deletes directory (must be empty)
* &lt;mark&gt;rm *file_name*&lt;/mark&gt; Deletes file_name
* &lt;mark&gt;cat *file_name*&lt;/mark&gt; Displays content of entire file_name
* &lt;mark&gt;less *file_name*&lt;/mark&gt; Displays content of file_name with paging
* &lt;mark&gt;man *command*&lt;/mark&gt; Displays the manual page for *command* with paging
* &lt;mark&gt;which *command*&lt;/mark&gt; Returns location of command
* &lt;mark&gt;exit&lt;/mark&gt; Quit shell and logout
* Much advanced power comes from learning *regular expressions*

---
background-image: url(pics/01-intro/WorkflowCluster.jpg)
background-position: top right
background-size: 20%

## Job Submission on Cluster

* Command line submission
* Write a shell script to request resources and submit a batch job (preferred)

.pull-left[
#### PBS (Karolina, Barbora)
&lt;mark&gt;qsub   *script.sh* 

&lt;mark&gt;qstat -u *uid*

&lt;mark&gt;qdel  *jobname*&lt;/mark&gt;

]
.pull-right[
#### Slurm (Sněhurka, Chimera)
&lt;mark&gt;sbatch  *script.sh* &lt;/mark&gt; 

&lt;mark&gt;squeue  -u *uid*&lt;/mark&gt;

&lt;mark&gt;scancel  *jobnumber*&lt;/mark&gt;

]  
&lt;br&gt;
* **module** to set software environment (PATH)
  * &lt;mark&gt;*module load R*&lt;/mark&gt;
  * &lt;mark&gt;*module load r*&lt;/mark&gt;
  * &lt;mark&gt;*module list*&lt;/mark&gt;
  * &lt;mark&gt;*module avail*&lt;/mark&gt;
  
---
background-image: url(pics/01-intro/WorkflowGit.jpg)
background-position: top left
background-size: 20%

.right[ 
# GitHub and git (laptop to cluster)
]

.w80.pull-left[
&lt;img src="pics/01-intro/Git_operations.svg" height="450" /&gt;

&lt;font size="-4"&gt;*By Daniel Kinzler - Own work, CC BY 3.0, https://commons.wikimedia.org/w/index.php?curid=25223536&lt;/font&gt;
]
.w20.pull-right[
&lt;br&gt;
&lt;img src="pics/01-intro/WorkflowCluster.jpg" height="80" /&gt;
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

&lt;img src="pics/01-intro/WorkflowLaptop.jpg" height="80" /&gt;

]
---
# Making it easy: set ssh keys

* A message encrypted by public key can be decrypted by private key
* Works like a single-use password generator and authenticator
.w80.pull-left[
&lt;img src="pics/01-intro/ssh-key-based-authentication.png" width="450" height="400" /&gt;

&lt;font size="-4"&gt;Graphic from &lt;/font&gt;
&lt;img src="pics/01-intro/ssh-credit.png" width="300" height="10" /&gt;
]
.w20.pull-right[
Your private key is protected on your local resource

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

Put your public key on the remote resource to enable easy access
]
---
## Demo ... `\(\qquad\)` Workflow
* Fork ROBUST2022 to your GitHub account
   * Login to GitHub
   * Navigate to RBigData/ROBUST2022
   * Click Fork button near top-right
* clone to New Project in RStudio
* Open Terminal window (ssh or putty)
* Login to cluster
* clone your ROBUST2022 (git clone ...)
* You are ready for development loop: 
   * edit -&gt; commit -&gt; push -&gt; pull -&gt; run -&gt; examine output
   
.pull-left[
&lt;img src="pics/01-intro/Workflow.jpg" height="250" /&gt;
]
.pull-right[
&lt;img src="pics/01-intro/BatchRonCluster.jpg" height="250" /&gt;
]

---
# Part III:  &lt;br&gt; &lt;br&gt; Parallel Hardware

---
background-image: url(pics/Mangalore/ParallelHardware/Slide7.png)
background-position: bottom
background-size: 90%

# Three Basic Concepts in Hardware

???
# GPU - NVIDIA
# MIC - Intel KNL - ARM

* Manycore chip with memory on the chip instead of separate memory boards: https://www.youtube.com/watch?v=eXhlDt2SD8o
  * A manycore that can act as a GPU
  * Multocores are MIMD and can run anything
  * GPU are SIMD and more limited
---
background-image: url(pics/Mangalore/ParallelHardware/Slide1.png)
background-position: bottom
background-size: 90%

# Three Basic Concepts in Hardware

???
# GPU - NVIDIA
# MIC - Intel KNL - ARM

* Manycore chip with memory on the chip instead of separate memory boards: https://www.youtube.com/watch?v=eXhlDt2SD8o
  * A manycore that can act as a GPU
  * Multocores are MIMD and can run anything
  * GPU are SIMD and more limited
---
background-image: url(pics/Mangalore/ParallelHardware/Slide2.png)
background-position: bottom
background-size: 90%

???
Graphics
---
background-image: url(pics/Mangalore/ParallelHardware/Slide3.png)
background-position: bottom
background-size: 90%

???
GPU - NVIDIA
MIC - Intel KNL
---
background-image: url(pics/Mangalore/ParallelHardware/Slide4.png)
background-position: bottom
background-size: 90%

---
background-image: url(pics/Mangalore/ParallelHardware/Slide5.png)
background-position: bottom
background-size: 90%

---
background-image: url(pics/Mangalore/ParallelHardware/Slide6.png)
background-position: bottom
background-size: 90%

---
# Part IV:  &lt;br&gt; &lt;br&gt; Parallel Software

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide2.png)
background-position: bottom
background-size: 90%

# Native Programming Mindset

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide3.png)
background-position: bottom
background-size: 90%

# Native Programming Models and Tools

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide4.png)
background-position: bottom
background-size: 90%

# 35+ Years of Parallel Computing Research

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide5.png)
background-position: bottom
background-size: 90%

# Last 15+ years of Advances

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide6.png)
background-position: bottom
background-size: 90%

## Distributed Programming Works in Shared Memory

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7.png)
background-position: bottom
background-size: 90%

# R Interfaces to Low-Level Native Tools
---
# Part V:  &lt;br&gt; &lt;br&gt; Shared Memory Tools
## Working with a single node
---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7shared.jpg)
background-position: bottom
background-size: 90%

# Working with a single node

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7fork.jpg)
background-position: bottom
background-size: 90%

# fork via mclapply
???
* we begin with `paralel`'s multicore parts
* continue with Foreign language via libraries (OpenBLAS, nvBLAS)
* go to SPMD MPI with collectives

* reverse of history - because we are used to a laptop 
* Distributed - some things are recomputed rather than communicated


---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7fork.jpg)
background-position: top right
background-size: 20%

# Unix `fork`
* A memory efficient parallelism on shared memory devices  

* Copy-on-write: copy page if forked process tries to write  

* R: **parallel** package `mclapply` and friends  
   * Use for numerical sections only
   * Avoid GUI, I/O, and graphics sections
* Convenient for data (not modified)

* Convenient for functional languages like R

* Careful with nested parallelism
  * OpenBLAS takes all cores by default
  * data.table switches to single threaded mode upon fork

.footnote[A deeper discussion of `fork` memory (if you have interest) on [YouTube](https://www.youtube.com/watch?v=8hVLcyBkSXY) by Chris Kanich (UIC)]

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7fork.jpg)
background-position: top right
background-size: 20%

# Copy-on-write

&lt;img src="pics/MC/Fork/Slide1.png" height="500" style="display: block; margin: auto;" /&gt;
???
* All done with pointers
* Memory is in pages
* Processes not aware of each other or other's memory use
* OS is aware of memory use
* 16 forks write = 16 copies of memory

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7fork.jpg)
background-position: top right
background-size: 20%

# Mapping Threads to Cores
### Theory and Reality

* Operating system manages core affinity
* Operating system tasks can compete
* Core switching occurs frequently

.pull-left[
&lt;img src="pics/WSC/iDVTstR_theory.jpg" height="350" style="display: block; margin: auto;" /&gt;
]
.pull-right[
&lt;img src="pics/WSC/iDVTstR_reality.jpg" height="350" style="display: block; margin: auto;" /&gt;
]

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7fork.jpg)
background-position: top right
background-size: 20%

### `R`: Drop-in replacements (almost) &lt;br&gt; for `lapply`, `mapply`, and `Map`

`mclapply(X, FUN, ...,`
`         mc.preschedule = TRUE, mc.set.seed = TRUE,`
`         mc.silent = FALSE, mc.cores = getOption("mc.cores", 2L),`
`         mc.cleanup = TRUE, mc.allow.recursive = TRUE, affinity.list = NULL)`

`mcmapply(FUN, ...,`
`         MoreArgs = NULL, SIMPLIFY = TRUE, USE.NAMES = TRUE,`
`         mc.preschedule = TRUE, mc.set.seed = TRUE,`
`         mc.silent = FALSE, mc.cores = getOption("mc.cores", 2L),`
`         mc.cleanup = TRUE, affinity.list = NULL)`

`mcMap(f, ...)`

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7fork.jpg)
background-position: top right
background-size: 20%

# Example Random forest Code
#### Letter recognition data ( `\(20\,000 \times 17\)` )
&lt;img src="pics/MC/ML_FreySlate1991.png" height="350" style="display: block; margin: auto;" /&gt;

.footnote[*Parallel Statistical Computing with R: An Illustration on Two Architectures [ 	arXiv:1709.01195](https://arxiv.org/abs/1709.01195)]
---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7fork.jpg)
background-position: top right
background-size: 20%

# Random Forest Classification

### Build many decision trees. Each tree from

* random subset of variables

* resampled (with replacement) data

### Use their majority votes to classify

---
background-image: url(pics/MC/Fork/Slide6.png)
background-position: bottom
background-size: 100%

# Pseudo Random Number Generators (RNG)
.pull-left[
* Guaranteed reproducibility
* Possibly overlapping streams
]
.pull-right[
* Reproducibility for same number of streams
* Guaranteed independent streams 
]
---
background-image: url(pics/MC/benchmark_mc.png)
background-position: bottom
background-size: 80%

# Example Random Forest Classification Code
#### Letter recognition data ( `\(20\,000 \times 17\)` ) - Scaling graph example

---
### `ROBUST2022/code/rf_serial.r`

```r
library(randomForest)
data(LetterRecognition, package = "mlbench")
set.seed(seed = 123)

n = nrow(LetterRecognition)
n_test = floor(0.2 * n)
i_test = sample.int(n, n_test)
train = LetterRecognition[-i_test, ]
test = LetterRecognition[i_test, ]

rf.all = randomForest(lettr ~ ., train, ntree = 500, norm.votes = FALSE)
pred = predict(rf.all, test)

correct = sum(pred == test$lettr)
cat("Proportion Correct:", correct/(n_test), "\n")
```

---
### `ROBUST2022/code/rf_mc.r`

```r
*library(parallel)
library(randomForest)
data(LetterRecognition, package = "mlbench")
*set.seed(seed = 123, "L'Ecuyer-CMRG")

n = nrow(LetterRecognition)
n_test = floor(0.2 * n)
i_test = sample.int(n, n_test)
train = LetterRecognition[-i_test, ]
test = LetterRecognition[i_test, ]

*nc = as.numeric(commandArgs(TRUE)[2])
*ntree = lapply(splitIndices(500, nc), length)
*rf = function(x, train) randomForest(lettr ~ ., train, ntree=x,
*                                    norm.votes = FALSE)
*rf.out = mclapply(ntree, rf, train = train, mc.cores = nc)
*rf.all = do.call(combine, rf.out)

*crows = splitIndices(nrow(test), nc)
*rfp = function(x) as.vector(predict(rf.all, test[x, ]))
*cpred = mclapply(crows, rfp, mc.cores = nc)
*pred = do.call(c, cpred)

correct &lt;- sum(pred == test$lettr)
cat("Proportion Correct:", correct/(n_test), "\n")
```
---
# Demo ... &lt;br&gt;&lt;br&gt; Random Forest via mclapply
---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7libs.jpg)
background-position: bottom
background-size: 90%

# Libraries via compiled language interfaces

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7libs.jpg)
background-position: top right
background-size: 20%

# R-LAPACK-BLAS

* BLAS: Basic Linear Algebra Subroutines - A matrix multiplication library
  * `%*%`, `crossprod()`, `sweep()`, `scale()`, and many more

* LAPACK: dense and banded matrix decomposition and more
  * `svd()`, `La.svd()`, `prcomp()`, `princomp()`, `qr()`, `solve()`, `chol()`, `norm()`, and many more
  * But not `lm()`, careful with `qr(x, LAPACK = TRUE)`: column pivoting

* Implementations: OpenBLAS, Intel MKL, Nvidia nvBLAS, Apple vecLib, AMD BLIS, Arm Performance Libraries

* **FlexiBLAS**: A BLAS and LAPACK wrapper library with runtime exchangeable backends
   * Great for benchmarking implementations
   * Great for dynamic core assignment

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7libs.jpg)
background-position: top right
background-size: 20%

# OpenBLAS

OpenBLAS is an optimized BLAS library based on GotoBLAS2 (2010, Kazushige Goto).

* [openblas.net](https://www.openblas.net)

* Optimizes algorithm to chip microarchitecture details of memory hierarchies (L1 cache, L2 cache, etc.) and register vector length

* IT4I FlexiBLAS: "OPENBLAS" backend

.footnote[
Wang Qian, Zhang Xianyi, Zhang Yunquan, Qing Yi, AUGEM: Automatically Generate High Performance Dense Linear Algebra Kernels on x86 CPUs, In the International Conference for High Performance Computing, Networking, Storage and Analysis (SC'13), Denver CO, November 2013.
]
---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7libs.jpg)
background-position: top right
background-size: 20%

### FlexiBLAS

`flexiblas_setup.r`

```r
library(flexiblas)
flexiblas_avail()
flexiblas_version()
flexiblas_current_backend()
flexiblas_list()
flexiblas_list_loaded()

getthreads = function() {
  flexiblas_get_num_threads()
}
setthreads = function(thr, label = "") {
  cat(label, "Setting", thr, "threads\n")
  flexiblas_set_num_threads(thr)
}
setback = function(backend, label = "") {
  cat(label, "Setting", backend, "backend\n")
  flexiblas_switch(flexiblas_load_backend(backend))
}
```

.footnote[
[https://github.com/Enchufa2/r-flexiblas](https://github.com/Enchufa2/r-flexiblas)  
[https://cran.r-project.org/package=flexiblas](https://cran.r-project.org/package=flexiblas)
]
---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7libs.jpg)
background-position: top right
background-size: 20%

# Demo ... &lt;br&gt;&lt;br&gt; FlexiBLAS

---
# The Singular Value Decomposition

`$$X = UDV^T$$`

For `\(n \geq p\)`,  

`\(U\)` is an `\(n\times p\)` orthogonal matrix of left singular vectors  

`\(V\)` is a `\(p\times p\)` orthogonal matrix of right singular vectors  

`\(D\)` is a `\(p\times p\)` diagonal matrix of singular values  

---
## Truncated SVD as Regression Basis Vectors

Suppose we have `\(n\)` images, each with `\(p\)` pixel values. The well known MNIST data set of digit images is an example with `\(n = 60\, 000\)` and `\(p = 784\,\, (28\times 28)\)`.

&lt;img src="mnist/RplotsDigits.png" height="300" /&gt;

Let `\(A\)` be the matrix of `\(n_A\)` images of a single digit, say digit zero, the pixel values of each image as a column.

---
## Truncated SVD as Regression Basis Vectors

Let `\(A\)` be the matrix of `\(n_A\)` images of a single digit, the pixel values of each image as a column.

The SVD of `\(A = UDV^T\)`.
If `\(u_i\)` and `\(v_i\)` are the columns of `\(U\)` and `\(V\)`, respectively, 
then 
`$$A = \sum_{i=1}^p d_i u_iv_i^T.$$`
and image `\(j\)` in column `\(a_j = \sum_{i=1}^p (d_i v_{ij})u_i.\)`

From matrix approximation, we know that this SVD can be truncated to some `\(k \ll p\)` components and still represent each image well. 
---
## Truncated SVD as Regression Basis Vectors

For some `\(k \ll p\)`, we have `\(a_j = \sum_{i=1}^k (d_iv_{ij})u_i.\)`

The `\(u_i\)` are basis functions constructed from data, a set of orthogonalized "images", which are the regressors and the `\(d_iv_{ij}\)` are the regression coefficients.

We can now look at classification of a new image of a digit by regressing it onto each of the 10 digit bases and classifying it into the category that fits best.

The tuning parameter `\(k\)` can be optimized with crossvalidation.

---
# Demo ... MNIST svd regression

.pull-left[
&lt;img src="mnist/one_basis95.png" height="400" style="display: block; margin: auto auto auto 0;" /&gt;
]
.pull-right[
&lt;img src="mnist/five_basis95.png" height="400" style="display: block; margin: auto auto auto 0;" /&gt;
]
---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7distributed.jpg)
background-position: bottom
background-size: 90%

# Part VI:  `\(\qquad\)`  Distributed Memory Tools

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7mpi.jpg)
background-position: bottom
background-size: 90%

# Message Passing Interface (MPI)
---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7mpi.jpg)
background-position: top right
background-size: 20%
# pbdR - MPI
&lt;img src="pics/01-intro/pbdRlib.jpg" height="100" style="display: block; margin: auto auto auto 0;" /&gt;

* MPI: Message Passing Interface - *de facto* standard for distributed communication in supercomputing

   * Used for data mostly via collective communication - high level

   * `pbdMPI`, `kazaam`, and `cop` R packages

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7mpi.jpg)
background-position: top right
background-size: 20%

# Single Program Multiple Data (SPMD)
#### Hello world!


```r
suppressMessages(library(pbdMPI))

my_rank = comm.rank()
ranks = comm.size()
msg = paste0("Hello World! My name is Empi", my_rank,
             ". We are ", ranks, " identical siblings.")
cat(msg, "\n")

finalize()
```

#### One code and a parallel mindset
#### A generalization of a serial code
#### Many rank-aware operations are automated
#### No manager, it is all cooperation
#### Explicit point-to-point communications are an advanced topic
---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7mpi.jpg)
background-position: top right
background-size: 20%

# High-level Collective Communications

`$$\bf A = \sum_{i=1}^nX_i$$`

#### `pbdMPI`: `\(\qquad\)` **reduce(X)** `\(\qquad\)` `\(\qquad\)` `\(\qquad\)` **allreduce(X**)
`$$\bf A = \left[ X_1 | X_2 | \cdots | X_n \right]$$`
#### `pbdMPI`: `\(\qquad\)` **gather(X)** `\(\qquad\)` `\(\qquad\)` `\(\qquad\)` **allgather(X**)
&lt;img src="pics/01-intro/RHistory3sub.png" height="250" style="display: block; margin: auto auto auto 0;" /&gt;

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7mpi.jpg)
background-position: top right
background-size: 20%

# Demo ... &lt;br&gt;&lt;br&gt; MPI communication in SPMD programming

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7mpi.jpg)
background-position: top right
background-size: 20%
# pbdR - ScaLAPACK - MPI
.pull-left[
&lt;img src="pics/01-intro/pbdRlib.jpg" height="100" style="display: block; margin: auto auto auto 0;" /&gt;
]
.pull-right[
**pbdr.org**
]

* ScaLAPACK: Scalable LAPACK - Distributed version of LAPACK (uses PBLAS/BLAS but not LAPACK)

   * 2d Block-Cyclic data layout - mostly automated in `pbdDMAT` package
   
   * BLACS: Communication collectives for distributed matrix computation
   * PBLAS: BLAS - distributed BLAS (uses shared memory BLAS within blocks)

   * `pbdDMAT` and `pbdML` R packages - most matrix operations identical to serial through overloading operators and `ddmatrix` class

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7mpi.jpg)
background-position: top right
background-size: 20%

## Constructing a Distributed Matrix from Data

* Each MPI rank reads different data in a contiguous block

.pull-left[
`$$\large\left[\begin{array}{ccc}a_{11}&amp;a_{12}&amp;a_{13}\\[1ex]a_{21}&amp;a_{22}&amp;a_{23}\\[1ex] a_{31}&amp;a_{32}&amp;a_{33}\end{array}\right]$$`  
`$$\large\left[\begin{array}{ccc}a_{11}&amp;a_{12}&amp;a_{13}\\[1ex]a_{21}&amp;a_{22}&amp;a_{23}\\[1ex] a_{31}&amp;a_{32}&amp;a_{33}\end{array}\right]$$`
]
.pull-right[
`$$\qquad$$`  

`\(\large a_{11}\;a_{12}\;a_{13}\;a_{21}\;a_{22}\;a_{23}\;a_{31}\;a_{32}\;a_{33}\)`  

C, C++, NumPy `\(\quad\)` **Row-Block**

`$$\qquad$$`  
`$$\qquad$$`  
`\(\large a_{11}\;a_{21}\;a_{31}\;a_{12}\;a_{22}\;a_{32}\;a_{13}\;a_{23}\;a_{33}\)`  

Fortran, R, Matlab  `\(\quad\)` **Column-Block**
]

* Each MPI rank adds attributes for global context

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7mpi.jpg)
background-position: top right
background-size: 20%

# Demo ... &lt;br&gt;&lt;br&gt; ScaLAPACK via pbdDMAT

---
## Randomized sketching algorithms
&lt;br&gt;&lt;br&gt;
Fast new alternatives to classical numerical linear algebra computations. 

&lt;br&gt;
Guarantees are given with probability statements instead of classical error analysis.

&lt;br&gt; &lt;br&gt;
Martinsson, P., &amp; Tropp, J. (2020). Randomized numerical linear algebra: Foundations and algorithms. Acta Numerica, 29, 403-572. [https://doi.org/10.48550/arXiv.2002.01387](https://doi.org/10.48550/arXiv.2002.01387)
---
`mnist_rsvd.R`

```r
source("mnist_read_mpi.R") # reads blocks of rows
suppressMessages(library(pbdDMAT))
suppressMessages(library(pbdML))
init.grid()

## construct block-cyclic ddmatrix
bldim = c(allreduce(nrow(my_train), op = "max"), ncol(my_train))
gdim = c(allreduce(nrow(my_train), op = "sum"), ncol(my_train))
dmat_train = new("ddmatrix", Data = my_train, dim = gdim, 
                 ldim = dim(my_train), bldim = bldim, ICTXT = 2)
cyclic_train = as.blockcyclic(dmat_train)

comm.print(comm.size())
t1 = as.numeric(Sys.time())
rsvd_train = rsvd(cyclic_train, k = 10, q = 3, retu = FALSE, retv = FALSE)
t2 = as.numeric(Sys.time())
t1 = allreduce(t1, op = "min")
t2 = allreduce(t2, op = "max")
comm.cat("Time:", t2 - t1, "seconds\n")

comm.cat("rsvd top 10 singular values:", rsvd_train$d, "\n")

finalize()
```

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7mpi.jpg)
background-position: top right
background-size: 20%

## Randomized SVD via subspace embedding
Given an `\(n\times p\)` matrix `\(X\)` and `\(k = r + 10\)`, where `\(r\)` is the *effective rank* of `\(X\)`:  
1. Construct a `\(p\times k\)` random matrix `\(\Omega\)`
2. Form `\(Y = X \Omega\)`
3. Decompose `\(Y = QR\)`

`\(Q\)` is an orthogonal basis for the columnspace of `\(Y\)`, which with high probability is the columnspace of `\(X\)`. To get the SVD of `\(X\)`:  
1. Compute `\(C= Q^TX\)`
2. Decompose `\(C = \hat{U}\Sigma V^T\)`
3. Compute `\(U = Q\hat{U}\)`
4. Truncate factorization to `\(r\)` columns

---
background-image: url(pics/Mangalore/ParallelSoftware/Slide7mpi.jpg)
background-position: top right
background-size: 20%

## Randomized SVD via subspace embedding
Given an `\(n\times p\)` matrix `\(X\)` and `\(k = r + 10\)`, where `\(r\)` is the *effective rank* of `\(X\)`:  
1. Construct a `\(p\times k\)` random matrix `\(\Omega\)`
2. Let `\(Y_0 = \Omega\)`
3. For `\(i\)` in `\(1:q\)`
   2. Decompose `\(Y_{i-1} = Q_{i}R_{i}\)`
   1. `\(Y_i = X(X^TQ_i)\)`
4. Decompose `\(Y_q = QR\)`

`\(Q\)` is an orthogonal basis for the columnspace of `\(Y\)`, which with high probability is the columnspace of `\(X\)`. To get the SVD of `\(X\)`:  
1. Compute `\(C= Q^TX\)`
2. Decompose `\(C = \hat{U}\Sigma V^T\)`
3. Compute `\(U = Q\hat{U}\)`
4. Truncate factorization to `\(r\)` columns



    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
